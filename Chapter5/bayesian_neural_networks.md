目前为止，我们对于神经网络的讨论集中于使用最大似然方法来确定网络的参数（权值和偏置）。正则化的最大似然方法可以看成MAP（maximum posterior）方法，其中正则化项可以被看成先验参数分布的对数。然而，在贝叶斯方法中，为了进行预测，我们需要对参数的概率分布进行积分或求和。    

在3.3节，我们研究了在高斯噪声假设下的简单线性回归模型的贝叶斯解。我们看到，后验概率分布（是一个高斯分布）可以精确计算，并且预测分布也具有解析解。在多层神经网络的情况下，网络函数对于参数值的高度非线性的性质意味着精确的贝叶斯方法不再可行。事实上，后验概率分布的对数是非凸的，对应于误差函数中的多个局部极小值。    

第10章将要讨论在贝叶斯神经网络中使用变分推断方法。这种方法使用了对后验概率的分解的高斯近似（Hinton and van Camp， 1993），也使用了一个具有完全协方差矩阵的高斯分布(Barber and Bishop，1998a; Barber and Bishop， 1998b)。但是，最完整的贝叶斯方法是构成了本节讨论基础的基于拉普拉斯近似的方法(MacKay，1992c; MacKay，
1992b)。我们会使用一个以真实后验概率的众数为中心的高斯分布来近似后验概率分布。此外，我们会假设这个高斯分布的协方差很小，从而网络函数关于参数空间的区域中的参数近似是线性的。在参数空间中，后验概率距离概率为零的状态相当远。使用这两个近似，我们会得到与之前讨论的线性回归和线性分类的模型相类似的模型，从而我们就可以利用之前得到了结果了。这样，我们可以使用模型证据的框架来对参数进行点估计，并比较不同的模型（如，有着不同的隐藏单元数量的网络）。首先，我们讨论回归问题的情形，然后，针对分类问题进行必要的修改。
