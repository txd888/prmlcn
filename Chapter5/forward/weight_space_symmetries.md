在我们考虑贝叶斯模型比较时，前馈神经网络的一个重要性质是对于多个不同的权向量$$ w $$的选择，网络会产生同样的从输入到输出的映射函数（Chen et al., 1993）。考虑图5.1展示的$$ M $$个隐含结点,激活函数是双曲正切函数，且层层之间完全连接的二层网络形式。如果我们改变作用于某个特定的隐含单元的所有权值及偏置的符号，那么，因为双曲线是奇函数，所以$$ tanh(-a) = -tanh(a)
$$，因此对于给定输入模式，隐含单元的激活的符号也会改变。这种变换可以通过改变所有从这个隐藏单元延伸出来的权值的符号进行精确的补偿。因此，改变特定的一组权值（包括偏置）的符号，网络表示的输入-输出映射是不变的，因此我们已经找到了两个不同的权向量产生同样的映射函数。对于$$ M $$个隐藏单元，将有$$ M $$个这样的“符号改变”对称性，因此，任何一个给定的权向量是$$ 2^M $$个等价的权向量中的一个。    

同样的，如果我们交换一个特定隐藏单元的所有权值（包括偏置），与一个不同的隐藏单元的对应权值（包括偏置），显然这不会改变网络输入-输出的映射函数，但是对应了一个不同的权向量。对于$$ M $$个隐藏节点，任何一个给定的权向量属于$$ M! $$个等价的权向量集合，它对应于$$ M! $$个不同的隐含单元的顺序。于是，网络的权空间整体对称性因子为$$ M!2^M $$。对于多于两层的网络，对称性的总数等于这些因子的乘积，每层隐含单元都有一个这样的因子。    

可以证明，对于权空间中的各种类型的对称性，这些因子都存在（除了由于权值的特定选择导致的偶然的对称性）。此外，对称性的存在不仅是因为双曲正切函数的特有性质，而是对一大类的激活函数都存在的性质（Ku ̇rkova ́ and Kainen, 199494）。虽然在5.7节我们会遇到需要考虑对称性的情形，但是在许多情况下权空间的这种对称性几乎没有实际用处。

