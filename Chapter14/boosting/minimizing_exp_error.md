提升方法最早起源于统计学习理论，得到了泛化误差的上界。然而，这些上界过于宽松，没有实际的价值。提升方法的实际表现要远优于上界给出的值。Friedman et al.(2000)根据对一个指数误差函数的顺序最小化，给出了提升方法的一个不同的且非常简单的表述。    

考虑下面定义的指数误差函数    

$$
E = \sum\limits_{n=1}^Nexp\{-t_nf_m(x_n)\} \tag{14.20}
$$    

其中$$ f_m(x) $$是一个根据基分类器$$ y_l(x) $$的线性组合定义的分类器，形式为    

$$
f_m(x) = \frac{1}{2}\sum\limits_{l=1}^m\alpha_ly_l(x) \tag{14.21}
$$    

$$ t_n \in \{−1, 1\} $$是训练集目标值。我们的目标是关于权系数$$ \alpha_l $$和基分类器$$ y_l(x) $$最小化$$ E $$。     

然而，我们不进行误差函数的全局最小化，而是假设基分类器$$ y_1(x),...,y_{m−1}(x) $$以及它们的系数$$ \alpha_1,...,\alpha_{m−1} $$固定，因此我们只关于$$ \alpha_m $$和$$ y_m(x) $$进行最小化。分离出基分类器$$ y_m(x) $$的贡献，我们可以将误差函数写成    

$$
\begin{eqnarray}
E &=& \sum\limits_{n=1}^N exp\left\{-t_nf_{m-1}(x_n) - \frac{1}{2}t_n\alpha_my_m(x_n)\right\} \\
&=& \sum\limits_{w_n^{(m)}}exp\left\{-\frac{1}{2}t_n\alpha_my_m(x_n)\right\} \tag{14.22}
\end{eqnarray}
$$    

其中，系数$$ w_n^{(m)} = exp\{−t_nf_{m-1}(x_n)\} $$可以被看做常数，因为我们只针对$$ \alpha_m $$和$$ y_m(x) $$进行最如果我们将被$$ y_m(x) $$正确分类的数据点的集合记作$$ T_m $$，并且将剩余的误分类的点记作$$ M_m $$，那么我们可以将误差函数写成下面的形式    

$$
\begin{eqnarray}
E &=& e^{-\alpha_m / 2}\sum\limits_{n \in T_m}w_n^{(m)}e^{\alpha_m / 2}\sum\limits_{n \in M_m}w_n^{(m)} \\
&=& (e^{\alpha_m / 2} - e^{-\alpha_m / 2})\sum\limits_{n=1}^Nw_n^{(m)}I(y_m(x_n) \neq t_n) + e^{-\alpha_m / 2}\sum\limits_{n=1}^Nw_n^{(m)} \tag{14.23}
\end{eqnarray}
$$     

当我们关于$$ y_m(x) $$进行最小化时，我们看到第二项是常数，因此这等价于对（14.15）进行最小化，因为在求和式前面的整个可乘性因子不影响最小值的位置。类似地，关于$$ \alpha_m $$最小化，我们得到了式（14.17），其中$$ \epsilon_m $$由式（14.16）定义。    

根据式（14.22），我们看到，找到$$ \alpha_m $$和$$ y_m(x) $$之后，数据点的权值使用下面的公式进行更新    

$$
w_n^{(m+1)} = w_n^{(m)} exp\left\{-\frac{1}{2}t_n\alpha_my_m(x_n)\right\} \tag{14.24}
$$    

使用下面的事实    

$$
t_ny_m(x_n) = 1 - 2I(y_m(x_n) \neq t_n) \tag{14.25}
$$    

我们看到在下一次迭代中，权值$$ w_n^{(m)} $$的更新为    

$$
w_n^{(m+1)} = w_n^{(m)} exp\left(-\frac{\alpha_m}{2}\right)exp\{\alpha_mI(y_m(x_n) \neq t_n)\} \tag{14.26}
$$    

由于$$ exp(− \alpha_m / 2) $$与$$ n $$无关，因此我们看到它对于所有数据点的权值都贡献一个相同的因子，从而可以丢弃。这样我们就得到了式（14.18）。    

最后，一旦所有的基分类器被训练完毕，新数据点通过计算由（14.21）定义的组合函数的符号进行分类。由于因子$$ 1 / 2 $$不影响符号，因此可以省略，得到了式（14.19）。
