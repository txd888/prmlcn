将模型组合方法与贝叶斯模型平均方法区分开是很重要的，这两种方法经常被弄混淆。为了理解二者的差异，考虑使用高斯混合模型进行概率密度估计的例子，其中若干的高斯分量以概率的方式进行组合。模型包含一个二值潜在变量$$ z $$，它表示混合分布中的哪个分量用于生成对应的数据点。因此，模型通过联合概率分布    

$$
p(x,z) \tag{14.2}
$$    

进行具体化，观测变量x上的对应的概率密度通过对潜在变量求和的方式得到，即    

$$
p(x) = \sum\limits_zp(x,z) \tag{14.3}
$$    

在我们的高斯混合模型的例子中，这会得到一个概率分布，形式为    

$$
p(x) = \sum\limits_{k=1}^K\pi_k\mathcal{N}(x|\mu_k,\Sigma_k) \tag{14.4}
$$    

各个符号的含义与之前相同。这是模型组合的一个例子。对于独立同分布的数据，我们可以使用式（14.3）将数据集$$ X = \{x_1,...,x_N\} $$的边缘概率写成下面的形式    

$$
p(X) = \prod\limits_{n=1}^Np(x_n) = \prod\limits_{n=1}^N\left[\sum\limits_{z_n}p(x_n,z_n)\right] \tag{14.5}
$$    

因此我们看到，每个观测数据点$$ x_n $$有一个对应的潜在变量$$ z_n $$。     

现在假设我们有若干个不同的模型，索引为$$ h = 1,...,H $$，先验概率分布为$$ p(h) $$。例如，一个模型可能是高斯混合模型，另一个模型可能是柯西分布的混合。数据集上的边缘概率分布为

$$
p(X) = \sum\limits_{h=1}^Hp(X|h)p(h) \tag{14.6}
$$    

这是贝叶斯模型平均的一个例子。这个在$$ h $$上的求和式的意义是，只有一个模型用于生成整个数 据集，$$ h $$上的概率分布仅仅反映了我们对于究竟是哪个模型用于生成数据的不确定性。随着数据集规模的增加，这个不确定性会减小，后验概率分布$$ p(h|X) $$会逐渐集中于模型中的某一个。    

这就强调了贝叶斯模型平均和模型组合的一个关键的不同，因为在贝叶斯模型平均中，整个数据集由单一的模型生成。相反，当我们像（14.5）那样组合多个模型时，我们看到数据集中的 不同的数据点可以由潜在变量$$ z $$的不同的值生成，即由不同的分量生成。    

虽然我们研究的是边缘概率分布$$ p(X) $$，但是同样的讨论适用于预测分布$$ p(x|X) $$以及诸如$$ p(t|x,X, T) $$这样的条件概率分布。
