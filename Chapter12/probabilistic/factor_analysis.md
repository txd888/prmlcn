因子分析是一个线性高斯潜在变量模型，它与概率PCA密切相关。它的定义与概率PCA的唯一差别是给定潜在变量$$ z $$的条件下观测变量x的条件概率分布的协方差矩阵是一个对角矩阵而不是各向同性的协方差矩阵，即     

$$
p(x|z) = \mathcal{N}(x|Wz + \mu, \Psi) \tag{12.64}
$$    

其中$$ \Psi $$是一个$$ D \times D $$的对角矩阵。注意，与概率PCA模型相同，因子分析模型假设在给定潜在变量$$ z $$的条件下，观测变量$$ x_1,...,x_D $$是独立的。本质上讲，因子分析模型这样解释数据的观测协方差结构：表示出矩阵$$ \Psi $$中与每个坐标相关联的独立的变量，然后描述矩阵$$ W $$中的变量之间的协方差。在因子分析的文献中，$$ W $$的列描述了观测变量之间的相关性关系，被称为因子载入（factor
loading）。$$ \Psi $$的对角元素，表示每个变量的独立噪声方差，被称为唯一性（uniqueness）。    

因子分析的起源于PCA一样早。关于因子分析的讨论可以参考Everitt(1984)、Bartholomew(1987) 和Basilevsky(1994)。Lawley(1953) 和Anderson(1963) 研究了因子分析与PCA之间的联系，证明了在似然函数的驻点处，对于一个$$ \Psi = \sigma^2I $$的因子分析模型，$$ W $$的列是样本协方差的 放缩后的特征向量，$$ \sigma^2 $$是丢弃的特征值的平均值。后来，Tipping and Bishop(1999b)证明，当组成$$ W $$的特征向量被选为主特征向量时，对数似然函数取得最大值。使用式（2.115），我们看到观测变量的边缘概率分布为$$ p(x) =
\mathcal{N}(x|\mu, C) $$，其中    

$$
C = WW^T + \Psi \tag{12.65}
$$    

与概率PCA相同，模型对于潜在空间中的选择具有不变性。历史上，在因子分析中，当我们试图给独立的因子（$$ z $$空间的坐标）赋予一个直观的意义时，因子分析就变成了争论的焦点。由于潜在空间中的选择不变性，因子分析中存在不可区分的问题，这会造成很多麻烦。然而，从我们的角度来说，我们将因子分析看成一种形式的潜在变量密度模型，其中我们感兴趣的是潜在空间的形式，而不是描述它的具体的坐标系的选择。
如果我们想要移除与潜在空间旋转相关联的模型的退化，那么我们必须考虑非高斯的潜在变量分布，这就产生了独立成分分析（ICA）模型。    

我们可以使用最大似然方法确定因子分析模型中的参数$$ \mu, W, \Psi $$的值。与之前一样，$$ \mu $$的解是样本的均值。然而，与概率PCA不同，$$ W $$的最大似然解不再具有解析解，因此必须迭代地求解。由于因子分析是一个潜在变量模型，因此可以使用与概率PCA模型中使用的EM算法相近似的EM算法来计算（Rubin and Thayer, 1982）。具体来说，E步骤方程为    

$$
\begin{eqnarray}
\mathbb{E}[z_n] &=& GW^T\Psi^{-1}(x_n - \bar{x}) \tag{12.66} \\
\mathbb{E}[z_nz_n^T] &=& G + \mathbb{E}[z_n]\mathbb{E}[z_n]^T \tag{12.67}
\end{eqnarray}
$$    

其中我们已经定义了    

$$
G = (I + W^T\Psi^{-1}W)^{-1} \tag{12.68}
$$    

注意，这里使用了一个$$ M \times M $$的矩阵求逆的表达方式，而不是$$ D \times D $$的表达方式（除非$$ \Psi $$是$$ D \times D $$的对角矩阵，此时求逆很简单，只需$$ O(D) $$次计算），这通常很方便，因为通常$$ M \ll D $$。类似的，M步骤方程的形式为    

$$
\begin{eqnarray}
W_{new} = \left[\sum\limits_{n=1}^N(x_n - \bar{x}\mathbb{E}[z_n]^T\right]\left[\sum\limits_{n=1}^N\mathbb{E}[z_nz_n^T]\right]^{-1} \tag{12.69} \\
\Psi_{new} = diag\left\{S - W^{new}\frac{1}{N}\sum\limits_{n=1}^N\mathbb{E}[z_n](x_n - \bar{x})^T\right\} \tag{12.70}
\end{eqnarray}
$$     

其中，“diag”算符将所有非对角线上的元素全部设置为0。使用本书中讨论过的方法，可以很容易的得到因子分析模型的贝叶斯方法。    

概率PCA与因子分析的另一个不同点关注的是数据集在变换下的行为的差异。对于PCA和概率PCA来说，如果我们在数据空间中选择坐标系，那么我们对数据的拟合不会发生任何变化， 但是$$ W $$会使用对应的选择矩阵进行变换。然而，对于因子分析来说，类似的性质是，如果我们对于数据向量进行一个分量之间的重新缩放，那么这种缩放可以被整合到对$$ \Psi $$的元素的重新缩放之中。
