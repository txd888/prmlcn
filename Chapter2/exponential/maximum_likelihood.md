现在，考虑使用最大似然来估计式（2.194）的通用指数族分布的参数向量$$ \eta $$的问题。对式（2.195）两边关于$$ \eta $$取梯度，得到：    

$$
\begin{eqnarray}
&\nabla& g(\eta)\int h(x)exp\{\eta^Tu(x)\}dx \\
&+& g(\eta)\int h(x)exp\{\eta^Tu(x)\}u(x)dx = 0 \tag{2.224}
\end{eqnarray}
$$

重排列，并再次使用式（2.195）得到：    

$$
-\frac{1}{g(\eta)}\nabla g(\eta) = g(\eta)\int h(x)exp\{\eta^Tu(x)\}u(x)dx = \mathbb{E}[u(x)] \tag{2.225}
$$

其中使用了式（2.194）。于是得到：    

$$
-\nabla\ln g(\eta) = \mathbb{E}[u(x)] \tag{2.226}
$$

注意，$$ u(x) $$的协方差可以由$$ g(\eta) $$的二阶导数来表达。对于高阶动差的情形类似。因此，如果能标准化来自指数族的分布，那么就可以通过简单的微分来找到它的动差。    

现在考虑一组独立同分布的数据$$ X=\{x_1,...,x_n\} $$，它的似然函数为：    

$$
p(X|\eta) = \left(\prod\limits_{n=1}^Nh(x_n)\right)g(\eta)^Nexp\left\{\eta^T\sum\limits_{n=1}^Nu(x_n)\right\} \tag{2.227}
$$

令$$ \ln p(X|\eta) $$关于$$ \eta $$的梯度为0，得到最大似然估计$$ \mu_{ML} $$满足

$$
-\nabla \ln g(\eta_{ML}) = \frac{1}{N}\sum\limits_{n=1}^N u(x_n) \tag{2.228}
$$

原则上可以通过解这个方程来得到$$ \eta_{ML} $$。最大似然估计的解只通过$$ \sum_n u(x_n) $$对数据产生依赖，所以它被称为分布（2.194）的充分统计量（sufficient statistic）。我们不需要存储整个数据集本身，只需要存储充分统计量的值即可。举个例子，对于伯努利分布，函数$$ u(x) $$就是$$ x $$，因此我们只需要存储数据点$$ \{x_n\} $$的和。而对于高斯分布$$ u(x) = (x, x^2)^T $$，因此我们应该同时存储$$ {x_n}, {x_n^2} $$的和。     

如果考虑极限$$ N \to \infty $$，那么式（2.228）的右手边就变成$$ \mathbb{E}[u(x)] $$，并与式（2.226）比较得到在这个极限下$$ \eta_{ML} $$等于真实的$$ \eta $$的值。    

实际上，这种充分性对于贝叶斯推断也成立，但是我们要把关于这一点的讨论推迟到第8章。那时，我们已经具备图模型的知识，因此能够更深刻地理解这些重要的概念。    


