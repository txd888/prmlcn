为了说明线性动态系统的概念，让我们考虑下面这个简单的例子，它经常在实际问题中出现。假设我们希望使用一个有噪声的传感器测量一个未知量$$ z $$的值，传感器返回一个观测值$$ x $$，表示$$ z $$的值加上一个0均值的高斯噪声。给定一个单次的测量，我们关于$$ z $$的最好的猜测是假设$$ z = x $$。然而，我们可以通过取多次测量然后求平均的方法提高我们对z的估计效果，因为随机噪声项倾向于彼此抵消。现在，让我们将情况变得更复杂。假设我们希望测量一个随着时间变化的量$$ z
$$。我们可以对进行常规的测量$$ x $$，从而我们得到了$$ x_1,...,x_n $$，我们希望找到对应的$$ z_1,...,z_n $$。如果我们简单地对测量求平均，那么由于随机噪声产生的误差会被消去，但是不幸的是我们会仅仅得到一个单一的平均估计，对$$ z $$的变化进行了平均，从而引入了一种新的误差。    

直观上讲，我们可以用下面的方式稍微好一些地完成这个任务。为了估计$$ z_N $$的值，我们只取最近的几次测量，例如$$ x_{N−L},..., x_N $$，然后求平均。如果$$ z $$的变化很慢，并且传感器的随机噪声的水平很高，那么选择一个相对长的窗又求平均是有意义的。相反，如果信号变化很快， 并且噪声水平相对较小，那么我们直接使用$$ x_N $$来估计$$ z_n $$会更合适。如果我们求加权平均，即最近的测量比之前的测量的贡献更大，那么或许效果会更好。    

虽然这种主观的讨论似乎是可行的，但是它并没有告诉我们如何求加权平均，并且任何一种人工设计的权值都很难成为最优的。幸运的是，我们可以更加系统化地解决这种问题，方法是定义一个概率模型，它描述了时间的演化和测量过程，然后应用了之前章节中讨论的推断和学习方法。这里，我们关注一类广泛使用的模型，被称为线性动态系统（linear dynamical system）。    

正如我们已经看到的，HMM对应于图13.5给出的状态空间模型，其中潜在变量是离散的，但是发射概率分布是任意的。这个图显然描述了相当大的一类概率分布，所有的都可以根据式（13.6）进行分解。我们现在考虑对潜在变量的其他类型的概率分布的推广。特别地，我们考虑连续潜在变量，其中加和-乘积算法的求和变成了积分。然而，推断算法的一般形式与隐马尔可夫模型相同。值得注意的很有趣的一点是，历史上，隐马尔可夫模型和线性动态系统是独立研究的。然而，一旦它们都用图模型进行表示，它们之间的深层关系就立刻变得明显了。    

一个重要的要求是，我们保留了推断的高效算法，它与链的长度是线性关系。例如，这要求，在给定观测$$ x_1,...,x_{n−1} $$的条件下，表示$$ z_{n−1} $$的后验概率分布的量$$ \hat{\alpha}(z_{n−1}) $$在与转移概率$$ p(z_n|z_{n−1}) $$和发射概率$$ p(x_n | z_n) $$相乘然后在$$ z_{n−1} $$上求和或积分之后，我们得到的$$ z_n $$上的概率分布与$$ \hat{\alpha}(z_{n−1}) $$上的概率分布具有相同的函数形式。也就是说，在每个阶段，概率分布不可以变得更复杂，而是仅仅在参数值上发生改变。毫不令人惊讶地说，在多次相乘之后具有这个性质的唯一的分布就是指数族分布的成员。    

这里，我们从实际应用的角度考虑一个最重要的例子，即高斯分布。特别地，我们考虑一个线性高斯状态空间模型，从而潜在变量$$ \{z_n\} $$以及观测变量$$ \{x_n\} $$是多元高斯分布，均值是图表示中的状态的线性函数。我们已经看到，线性高斯单元的有向图等价于所有变量上的联合高斯分布。此外，诸如$$ \hat{\alpha}(z_n)
$$的边缘概率分布也是高斯分布，从而信息的函数形式被保留了下来，我们可以得到一个高效的推断算法。相反，假设发射概率密度$$ p(x_n|z_n) $$由$$ K $$个高斯分布混合而成， 每个高斯分布的均值都是$$ z_n $$的线性函数，那么即使$$ \hat{\alpha}(z_1) $$是一个高斯分布，$$ \hat{\alpha}(z_2) $$会是$$ K $$个高斯分布的混合，$$ \hat{\alpha}(z_3) $$会是$$ K^2 $$个高斯分布的混合，以此类推，因此精确的推断没有实际价值。     

我们已经看到隐马尔科夫模型可以看成第9章的混合模型的一个推广，它允许数据之间具有顺序相关性。类似的，我们可以将线性动态系统看成第12章的连续潜在变量模型（如概率PCA和因子分析）的推广，每对结点$$ \{z_n, x_n\} $$表示那个特定的观测下的一个线性高斯潜在变量模型。然而，潜在变量$$ \{z_n\} $$不再被看成独立的，而是构成了一个马尔科夫链。    

由于模型由树结构的有向图表示，因此推断问题可以使用加-乘算法高效地求解。前向递归方程，类似于隐马尔可夫模型的$$ \alpha $$信息，被称为Kalman滤波(Kalman filter)方程(Kalman， 1960; Zarchan and Musoff， 2005)，后向递归方程，类似于β信息，被称为Kalman平滑(Kalman smoother)方程，或者Rauch-Tung-Striebel (RTS)方程(Rauch et al.， 1965)。Kalman滤波被广泛应用于许多实时跟踪应用中。    

由于线性动态系统是一个线性高斯模型，因此在所有变量上的联合概率分布以及边缘分布和条件分布都是高斯分布。它遵循下面的事实：单独地概率最大的潜在变量值组成的序列与概率最大的潜在变量序列相同。因此对于线性动态系统，无需考虑与维特比算法类似的算法。    

由于模型的条件概率分布是高斯分布，因此我们可以将转移分布和发射分布写成一般的形式    

$$
\begin{eqnarray}
p(z_n|z_{n-1} = \mathcal{N}(z_n|Az_{n-1},\Gamma) \tag{13.75} \\
p(x_n|z_n) = \mathcal{N}(x_n|Cz_n,\Sigma) \tag{13.76}
\end{eqnarray}
$$    

初始潜在变量也服从高斯分布，我们写成    

$$
p(z_1) = \mathcal{N}(z_1|\mu_0,P_0) \tag{13.77}
$$    

注意，为了简化记号，我们省略了高斯分布的均值中额外的可加性常数。事实上，如果必要的话，加上这些常数是很容易的。传统上，这些概率分布通常使用噪声线性方程表示为一个等价的形式，噪声线性方程为    

$$
\begin{eqnarray}
z_n = Az_{n-1} w_n \tag{13.78} \\
x_n = Cz_n + v_n \tag{13.79} \\
z_1 = \mu_0 + u \tag{13.80}
\end{eqnarray}
$$    

其中噪声项的概率分布为    

$$
\begin{eqnarray}
w \sim \mathcal{N}(w|0, \Gamma) \tag{13.81} \\
v \sim \mathcal{N}(v|0, \Sigma) \tag{13.82} \\
u \sim \mathcal{N}(u|0, P_0) \tag{13.83} 
\end{eqnarray}
$$    

模型的参数被记作$$ \theta = \{A, \Gamma, C, \Sigma, \mu_0, P_0\} $$，可以通过EM算法使用最大似然的方法确定。在E步骤中，我们需要求解确定潜在变量的局部后验边缘概率的推断问题，这可以使用加-乘算法高效地求出，我们将在下一节讨论。
