多变量概率分布的一个重要概念是条件独立（conditional independence）（Dawid, 1980）。考虑三个变量$$ a, b, c $$，并且假设给定$$ b, c $$的条件下$$ a $$的条件概率分布不依赖于$$ b $$的值，即

$$
p(a|b,c) = p(a|c) \tag{8.20}
$$

我们说，给定$$ c $$的条件下，$$ a $$条件独立于$$ b $$。那么我们可以用

$$
\begin{eqnarray}
p(a,b|c) &=& p(a|b,c)p(b|c) \\
&=& p(a|c)p(b|c) \tag{8.21}
\end{eqnarray}
$$

来表示$$ c $$为条件下的$$ a, b $$的联合分布。其中我们使用了概率的乘法规则以及式（8.20）。因此，我们看到了，以$$ c $$为条件，$$ a, b$$的联合概率分布分解为了$$ a $$的边缘分布和$$ b $$的边缘分布的乘积（都以$$ c $$为条件）。注意，我们对于独立性的定义需要式（8.20）对于$$ c $$的所有可能值成立，或等价地需要式（8.21）对于$$ c $$的所有可能值成立，而不是对于某些特定的$$ c $$值。我们有时会使用条件独立的一种简洁记号（Dawid, 1979），即

$$
a \perp b | c \tag{8.22}
$$

表示给定$$ c $$的条件下$$ a,b $$条件独立，等价于式（8.20）。 在模式识别中使用概率模型时，条件独立性起着重要的作用。它简化了模型的结构，降低了模型的训练和推断的计算量。我们稍后会看到这样的例子。    

如果一组变量的联合概率分布的表达式是根据条件概率分布的乘积表示的（即有向图的数学表达形式），那么原则上我们可以通过重复使用概率的加和规则和乘积规则测试是否具有潜在的条件独立性。在实际应用中，这种方法非常耗时。图模型的一个重要的优雅的特征是，联合概率分布的条件独立性可以直接从图中读出来，不用进行任何计算。完成这件事的一般框架被称为“d-划分”（d-separation），其中“d”表示“有向（directed）”（Pearl, 1988）。这里，我们非形式化地介绍了d-划分的概念，给出了d-划分准则的一个一般叙述。形式化的证明可以参考Lauritzen(1996)。
