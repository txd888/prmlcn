在多类别分类的广义模型讨论中，我们看到对于一大类概率分布来说，后验概率由特征变量的线性函数的softmax变换给出，即

$$
p(C_k|\phi) = y_k(\phi) = \frac{exp(a_k)}{\sum_j exp(a_j)} \tag{4.104}
$$

其中的“激活”$$ a_k $$由

$$
a_k = w_k^T\phi \tag{4.105}
$$

给出。我们使用最大似然来分别确认类的条件密度和先验，然后使用贝叶斯定理来得到对应的后验概率，从而隐式的确定了参数$$ \{w_k\} $$。现在我们考虑使用最大似然直接来确定这个模型的参数$$ \{w_k\} $$。为了达到这个目的，我们需要对$$ y_k $$关于所有的“激活”$$ a_j $$求导，它们由

$$
\frac{\partial y_k}{\partial a_j} = y_k(I_{kj} - y_j) \tag{4.106}
$$

其中$$ I_{kj} $$是单位矩阵的元素。    

接下来，我们写出似然函数。使用“1-of-K”表达方式是最容易的。似然函数由

$$
p(T|w_1,...,w_K) = \prod\limits_{n=1}^N\prod\limits_{k=1}^Kp(C_k|\phi_n)^{t_{nk}} = \prod\limits_{n=1}^N\prod\limits_{k=1}^Ky_{nk}^{t_{nk}} \tag{4.107}
$$

其中$$ y_{nk} = y_k(\phi_n) $$，且$$ T $$是元素为目标变量$$ t_{nk} $$的$$ N \times K $$的矩阵。取对数的负得到

$$
E(w_1,...,w_K) = -\ln p(T|w_1,...,w_K) = -\sum\limits_{n=1}^N\sum\limits_{k=1}^K t_{nk}\ln y_{nk} \tag{4.108}
$$

这被称为多类别分类问题的交叉熵（cross-entropy）误差函数。    

现在我们关于其中一个参数向量$$ w_j $$对误差函数求导。使用式（4.106）给出的softmax函数的导数结果，我们得到

$$
\nabla_{w_j}E(w_1,...,w_k) = \sum\limits_{n=1}^N(y_{nj}-t_{nj})\phi_n \tag{4.109}
$$

其中我们使用了$$ \sum_kt_{nk} = 1 $$。再一次，我们看到了在线性模型的平方和误差函数以及logistic回归模型的误差函数中都出现过的误差$$ (y_{nj} − t_{nj}) $$与基函数$$ \phi_n $$的乘积的梯度形式。同样的，我们可以将这个公式用于每次只出现一个模式，每个权向量都使用式（3.22）更新的顺序算法。    

我们已经看到，对于数据点$$ n $$，线性回归模型的对数似然函数关于参数向量$$ w $$的导数具有“误差”$$ y_n - t_n $$乘以特征向量$$ \phi_n $$的形式。同样的，对于logistic sigmoid激活函数与交叉熵误差函数（4.90）的组合，以及多类交叉熵误差函数（4.108）的softmax激活函数，我们也得到了相同的函数形式。这是一个更一般的结果的例子，正如我们将在4.3.6节看到的那样。    

为了找到批量算法，我们再次使用Newton-Raphson更新来获得多类别问题的对应的IRLS算法。这需要求出块$$ i,j $$为

$$
\nabla_{w_k}\nabla_{w_j}E(w_1,...,w_K) = -\sum\limits_{n=1}^Ny_{nk}(I_{kj}-y_{nj})\phi_n\phi_n^T \tag{4.110}
$$

与二分类问题一样，对类别logistic回归模型的Hessian矩阵是正定的，因此误差函数有唯一的最小值。多类别情况下的IRLS的实践细节可以参考Bishop and Nabney (2008)。
