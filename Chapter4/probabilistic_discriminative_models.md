对于二分类问题，我们已经看到，对于类条件分布$$ p(x|C_k) $$的很多选择，类$$ C_1 $$的后验概率都可以写成$$ x $$的线性函数上的logistic sigmoid。同样的，对于多类别情形，类$$ C_k $$的后验概率由$$ x $$的线性函数的softmax变换给出。对于类条件密度$$ p(x|C_k) $$的具体选择，使用最大似然来确定密度的参数，以及类先验$$ p(C_k) $$，然后使用贝叶斯定理求得类后验概率。    

然而，另一种方法是显示地使用广义线性模型的函数形式，然后使用最大似然来确定它的参数。我们将会看到，一种被称为迭代重加权最小二乘（iterative reweighted least squares）或简称IRLS的求解这样方法的高效算法。    

寻找广义线性模型参数的间接方法是是通过分别拟合类条件密度和类先验，然后使用贝叶斯方法。由于我们可以从这样的模型的边缘分布$$ p(x) $$中取出$$ x $$的值来人工生成数据，所以它是一个生成模型。在直接方法中，我们最大化由条件概率分布$$ p(C_k|x) $$定义的似然函数。这是一种判别式训练。正如我们稍后会看到的那样，判别方法的一个优点是通常需要确定的调节参数更少。而且它会提升预测表现也会提升，尤其是当类条件密度的假设没有很好的近似真实的分布的时候。
