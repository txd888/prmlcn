本章一直关注由固定的非线性基函数的线性组合组成的模型。我们已经知道，假设参数为线性的，能引出包括最小二乘问题的解析解，以及好用的贝叶斯方法等一系列有用的性质。此外，通过选择合适的基函数，我们可以建立输入向量到目标之间的任意非线性映射。在下一章中，我们会研究用于分类的类似的模型。    

因此，似乎这样的线性模型构成了解决模式识别问题的通用框架。不幸的是，线性模型有一些致命的缺点，这使我们在后续的章节中要转而关注更加复杂的模型，例如支持向量机和神经网络。    

问题产生的主要原因是在观测到任何数据之前，基函数就已经被固定下来了，而这正是 1.4节讨论的维度灾难问题的一种体现。这导致基函数的数量随着输入空间的维度$$ D $$迅速（通常是指数方式）增长。    

幸运的是，真实数据集有两个性质可以帮助我们缓解这个问题。第一，数据向量$$ \{x_n\}
$$通常位于一个与输入变量强相关的，本身的维度小于输入空间的维度的非线性流形附近。在第12章中讨论手写数字识别时，我们将看到这样的一个例子。如果我们使用局部基函数，那么我们可以让它们只分布在输入空间中包含数据的区域。这种方法被用在径向基函数网络中，也被用在支持向量机和相关向量机当中。神经网络模型使用具有sigmoid非线性的，可调节的基函数。可通过调节参数意味着，在输入空间的区域中，它可以使基函数按照数据流形发生变化。第二，目标变量可能只依赖于数据流形中的少量可能的方向。利用这个性质，神经网络可以选择基函数在输入空间中产生响应的方向。
